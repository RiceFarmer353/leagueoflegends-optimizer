{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a local file called matchups.csv. This file is local and should be in the same directory as the notebook in order to be properly imported.\n",
    "\n",
    "This analysis method is recommended as it's easier. Everything can be uploaded to an OCI Data Science environment.\n",
    "\n",
    "This method is optional and should only work once all prerequisites and installation steps are finished. If you are starting out with the repository, it's recommended to check out hol1_offline_analysis.ipynb instead.\n",
    "\n",
    "Configuration parameters can be currently be found and populated in config.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T23:06:00.369177Z",
     "start_time": "2021-12-01T23:06:00.129963Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import os\n",
    "pd.set_option('float_format', '{:f}'.format)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T23:06:19.713953Z",
     "start_time": "2021-12-01T23:06:00.370727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nimport os\\nos.environ['PATH']='/home/ubuntu/miniconda3/bin:$PATH' # set your own python environment\\n\\n\\n!python -m pip install -U pip\\n!python -m pip install -U setuptools wheel\\n!pip install pandas_profiling\\n## install packages\\n!pip install -q scikit-learn\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute if you're missing any of these libraries. This is a way to install them.\n",
    "'''\n",
    "\n",
    "import os\n",
    "os.environ['PATH']='/home/ubuntu/miniconda3/bin:$PATH' # set your own python environment\n",
    "\n",
    "\n",
    "!python -m pip install -U pip\n",
    "!python -m pip install -U setuptools wheel\n",
    "!pip install pandas_profiling\n",
    "## install packages\n",
    "!pip install -q scikit-learn\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T23:07:47.454290Z",
     "start_time": "2021-12-01T23:07:20.819491Z"
    }
   },
   "outputs": [],
   "source": [
    "# We read the dataset from the local file\n",
    "df = pd.read_csv('matchups.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T23:07:49.764599Z",
     "start_time": "2021-12-01T23:07:48.074703Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T23:17:54.011355Z",
     "start_time": "2021-12-01T23:07:49.766217Z"
    }
   },
   "outputs": [],
   "source": [
    "#report = ProfileReport(df, title=\"Matchups Exploration\", html={'style': {'full_width': True}})\n",
    "#report #uncomment to display all.\n",
    "\n",
    "#report.to_notebook_iframe() # to_file('output.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>champ1</th>\n",
       "      <th>champ2</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Ziggs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Pyke</td>\n",
       "      <td>Sett</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Diana</td>\n",
       "      <td>Viego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Jayce</td>\n",
       "      <td>Gwen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pantheon</td>\n",
       "      <td>Zed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id    champ1 champ2  win\n",
       "0         0    Ezreal  Ziggs    1\n",
       "1         1      Pyke   Sett    1\n",
       "2         2     Diana  Viego    1\n",
       "3         3     Jayce   Gwen    1\n",
       "4         4  Pantheon    Zed    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We read the dataset from the local file, after taking a look at the original dataset.\n",
    "df = pd.read_csv('1v1.csv', sep=',')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ezreal', 'Pyke', 'Diana', 'Jayce', 'Pantheon', 'Galio',\n",
       "       'Mordekaiser', 'Anivia', 'Kalista', 'Brand', 'LeeSin', 'Katarina',\n",
       "       'Jinx', 'Nami', 'Sylas', 'Irelia', 'Lucian', 'Zyra', 'Kayn', 'Zac',\n",
       "       'Qiyana', 'Jhin', 'Caitlyn', 'Morgana', 'Viego', 'Tryndamere',\n",
       "       'Kassadin', 'Camille', 'Leblanc', 'Draven', 'Syndra', 'Ziggs',\n",
       "       'Bard', 'XinZhao', 'Nocturne', 'Yasuo', 'Riven', 'Corki', 'Karma',\n",
       "       'Elise', 'MonkeyKing', 'Sivir', 'Blitzcrank', 'Jax', 'Zilean',\n",
       "       'Ashe', 'Velkoz', 'DrMundo', 'Ekko', 'Thresh', 'Nunu', 'Sett',\n",
       "       'Khazix', 'Cassiopeia', 'Kaisa', 'Nautilus', 'Gwen', 'Graves',\n",
       "       'Volibear', 'KogMaw', 'Lulu', 'Ryze', 'Lux', 'Rengar', 'Alistar',\n",
       "       'Karthus', 'Gragas', 'Shen', 'Neeko', 'TahmKench', 'Akali',\n",
       "       'Vayne', 'Seraphine', 'Gnar', 'Tristana', 'Leona', 'Yone',\n",
       "       'Viktor', 'Skarner', 'Garen', 'Zed', 'Soraka', 'Talon', 'Fiora',\n",
       "       'TwistedFate', 'MissFortune', 'Veigar', 'Hecarim', 'Shyvana',\n",
       "       'Aatrox', 'Sion', 'Kayle', 'Poppy', 'Rumble', 'Xerath', 'Orianna',\n",
       "       'Janna', 'Renekton', 'Rakan', 'Maokai', 'MasterYi', 'AurelionSol',\n",
       "       'Yuumi', 'Shaco', 'Lissandra', 'Zoe', 'Senna', 'Taliyah', 'Lillia',\n",
       "       'Warwick', 'Varus', 'Darius', 'Udyr', 'Samira', 'Amumu',\n",
       "       'Aphelios', 'Evelynn', 'Swain', 'Twitch', 'RekSai', 'Vi', 'Yorick',\n",
       "       'Akshan', 'Vladimir', 'Malphite', 'FiddleSticks', 'Ornn',\n",
       "       'Kindred', 'JarvanIV', 'Rell', 'Olaf', 'Urgot', 'Nidalee',\n",
       "       'Heimerdinger', 'Ahri', 'Malzahar', 'Trundle', 'Gangplank',\n",
       "       'Annie', 'Rammus', 'Xayah', 'Azir', 'Taric', 'Teemo', 'Sona',\n",
       "       'Nasus', 'Kennen', 'Braum', 'Ivern', 'Chogath', 'Fizz', 'Quinn',\n",
       "       'Kled', 'Singed', 'Sejuani', 'Illaoi'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['champ1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> ['Ezreal', 'Pyke', 'Diana', 'Jayce', 'Pantheon', 'Galio', 'Mordekaiser', 'Anivia', 'Kalista', 'Brand', 'LeeSin', 'Katarina', 'Jinx', 'Nami', 'Sylas', 'Irelia', 'Lucian', 'Zyra', 'Kayn', 'Zac', 'Qiyana', 'Jhin', 'Caitlyn', 'Morgana', 'Viego', 'Tryndamere', 'Kassadin', 'Camille', 'Leblanc', 'Draven', 'Syndra', 'Ziggs', 'Bard', 'XinZhao', 'Nocturne', 'Yasuo', 'Riven', 'Corki', 'Karma', 'Elise', 'MonkeyKing', 'Sivir', 'Blitzcrank', 'Jax', 'Zilean', 'Ashe', 'Velkoz', 'DrMundo', 'Ekko', 'Thresh', 'Nunu', 'Sett', 'Khazix', 'Cassiopeia', 'Kaisa', 'Nautilus', 'Gwen', 'Graves', 'Volibear', 'KogMaw', 'Lulu', 'Ryze', 'Lux', 'Rengar', 'Alistar', 'Karthus', 'Gragas', 'Shen', 'Neeko', 'TahmKench', 'Akali', 'Vayne', 'Seraphine', 'Gnar', 'Tristana', 'Leona', 'Yone', 'Viktor', 'Skarner', 'Garen', 'Zed', 'Soraka', 'Talon', 'Fiora', 'TwistedFate', 'MissFortune', 'Veigar', 'Hecarim', 'Shyvana', 'Aatrox', 'Sion', 'Kayle', 'Poppy', 'Rumble', 'Xerath', 'Orianna', 'Janna', 'Renekton', 'Rakan', 'Maokai', 'MasterYi', 'AurelionSol', 'Yuumi', 'Shaco', 'Lissandra', 'Zoe', 'Senna', 'Taliyah', 'Lillia', 'Warwick', 'Varus', 'Darius', 'Udyr', 'Samira', 'Amumu', 'Aphelios', 'Evelynn', 'Swain', 'Twitch', 'RekSai', 'Vi', 'Yorick', 'Akshan', 'Vladimir', 'Malphite', 'FiddleSticks', 'Ornn', 'Kindred', 'JarvanIV', 'Rell', 'Olaf', 'Urgot', 'Nidalee', 'Heimerdinger', 'Ahri', 'Malzahar', 'Trundle', 'Gangplank', 'Annie', 'Rammus', 'Xayah', 'Azir', 'Taric', 'Teemo', 'Sona', 'Nasus', 'Kennen', 'Braum', 'Ivern', 'Chogath', 'Fizz', 'Quinn', 'Kled', 'Singed', 'Sejuani', 'Illaoi']\n"
     ]
    }
   ],
   "source": [
    "champ_list = df['champ1'].unique().tolist()\n",
    "\n",
    "print(type(champ_list), champ_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['match_id', 'champ1', 'champ2', 'win'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) # we have 4 columns, 'win' is what we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1288773 entries, 0 to 1288772\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   match_id  1288773 non-null  int64 \n",
      " 1   champ1    1288773 non-null  object\n",
      " 2   champ2    1288773 non-null  object\n",
      " 3   win       1288773 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 39.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually we check for null values. In this case we don't have any null values in the dataset,\n",
    "# so this operation is redundant in this case\n",
    "\n",
    "# df = df.dropna() # we drop null values and corresponding rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop match_id column as it's a String that provides no value\n",
    "df.drop(['match_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df.sample(frac=0.8, random_state=0) # 80-20 train-test splitting.\n",
    "test_dataset = df.drop(train_dataset.index) # drop all rows present in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features (what we use to predict) from labels (what we want to predict)\n",
    "# We want to predict the 'win' variable.\n",
    "# The rest of variables will be inputs.\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('win') # returns column 'win'\n",
    "test_labels = test_features.pop('win') # returns column 'win'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le = le.fit(champ_list) # fit the label encoder with the whole champion list.\n",
    "\n",
    "train_features = train_features.apply(lambda x: le.transform(x))\n",
    "test_features = test_features.apply(lambda x: le.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51541224 0.48458776]\n",
      " [0.51096743 0.48903257]\n",
      " [0.51515081 0.48484919]\n",
      " ...\n",
      " [0.51376513 0.48623487]\n",
      " [0.51221206 0.48778794]\n",
      " [0.51455823 0.48544177]]\n",
      "0.5132888077608733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_features, train_labels)\n",
    "# score(X, y[, sample_weight]): Return the mean accuracy on the given test data and labels\n",
    "print(logreg.predict_proba(train_features))\n",
    "print(logreg.score(train_features, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>champ1</th>\n",
       "      <th>champ2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   champ1  champ2\n",
       "0      28      48\n",
       "1      44      13\n",
       "2       6     139\n",
       "3      35      46\n",
       "4     142       5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {\n",
    "    'champ1': ['Ezreal', 'Janna', 'Anivia', 'Gnar', 'Warwick'],\n",
    "    'champ2': ['Jhin', 'Blitzcrank', 'Viktor', 'Jax', 'Amumu']\n",
    "\n",
    "}\n",
    "'''\n",
    "['Jhin', 'Janna', 'Anivia', 'Gnar', 'Warwick']\n",
    "['Tristana', 'Sona', 'Ahri', 'Riven', 'Nidalee']\n",
    "['Sivir', 'Blitzcrank', 'Viktor', 'Jax', 'Amumu']\n",
    "'''\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "new_df = new_df.apply(lambda x: le.transform(x)) # we use the previously created label encoder\n",
    "\n",
    "scaled = scaler.fit_transform(new_df)\n",
    "\n",
    "new_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48727064, -0.04620625],\n",
       "       [-0.14829976, -0.78130573],\n",
       "       [-0.9533556 ,  1.8650524 ],\n",
       "       [-0.33897088, -0.08821194],\n",
       "       [ 1.92789687, -0.94932847]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled # check what happens with scaling (example)\n",
    "\n",
    "# e.g. 'Tristana' becomes 0.9229278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1]\n",
      "[[0.57085824 0.42914176]\n",
      " [0.496072   0.503928  ]\n",
      " [0.73050918 0.26949082]\n",
      " [0.56122379 0.43877621]\n",
      " [0.3951099  0.6048901 ]]\n"
     ]
    }
   ],
   "source": [
    "result = logreg.predict(new_df)\n",
    "print(result)\n",
    "\n",
    "detailed_result = logreg.predict_proba(new_df)\n",
    "\n",
    "print(detailed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57085824 0.42914176]\n",
      "[0.496072 0.503928]\n",
      "[0.73050918 0.26949082]\n",
      "[0.56122379 0.43877621]\n",
      "[0.3951099 0.6048901]\n",
      "3 2 [7.085823690873272, -0.3928003875371511, 23.05091752259806, 6.122379069905581, -10.489009544500005]\n",
      "Team 1 most likely to win with an additional probability of 25.37731035133976\n"
     ]
    }
   ],
   "source": [
    "def find_winner(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def find_winner_new(lst):\n",
    "    count_team_1 = 0; count_team_2 = 0\n",
    "    count = 0\n",
    "    extra_probabilities = list()\n",
    "    for x in lst:\n",
    "        print(x)\n",
    "        additional_prob = (x[0] - 0.5) * 100\n",
    "        extra_probabilities.append(additional_prob)\n",
    "        if x[0] >= x[1]:\n",
    "            #print('Champ 1 most likely to win ({}% additional probability)'.format(additional_prob))\n",
    "            count_team_1 += 1\n",
    "        else:\n",
    "            #print('Champ 2 most likely to win ({}% additional probability)'.format((x[1]-x[0])*100))\n",
    "            count_team_2 += 1\n",
    "    return count_team_1, count_team_2, extra_probabilities\n",
    "\n",
    "\n",
    "# we take the mode as a \"normalizer\"\n",
    "team_1, team_2, probabilities = find_winner_new(detailed_result)\n",
    "print(team_1, team_2, probabilities)\n",
    "\n",
    "#if sum(probabilities) > 0:\n",
    "if team_1 > team_2:\n",
    "    print('Team 1 most likely to win with an additional probability of {}'.format(sum(probabilities)))\n",
    "else:\n",
    "    print('Team 2 most likely to win with an additional probability of {}'.format(sum(probabilities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>champ1</th>\n",
       "      <th>champ2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Jhin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Janna</td>\n",
       "      <td>Blitzcrank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anivia</td>\n",
       "      <td>Viktor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gnar</td>\n",
       "      <td>Jax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warwick</td>\n",
       "      <td>Amumu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    champ1      champ2\n",
       "0   Ezreal        Jhin\n",
       "1    Janna  Blitzcrank\n",
       "2   Anivia      Viktor\n",
       "3     Gnar         Jax\n",
       "4  Warwick       Amumu"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we make the inverse transform to convert to human-readable format again\n",
    "inverse_prediction = new_df.apply(lambda x: le.inverse_transform(x))\n",
    "\n",
    "inverse_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted winner is 0          Jhin\n",
      "1    Blitzcrank\n",
      "2        Viktor\n",
      "3           Jax\n",
      "4         Amumu\n"
     ]
    }
   ],
   "source": [
    "if result[0] == 1:\n",
    "    print('Predicted winner is {}'.format(str(inverse_prediction['champ1'].to_string())))\n",
    "else:\n",
    "    print('Predicted winner is {}'.format(str(inverse_prediction['champ2'].to_string())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda",
   "language": "python",
   "name": "miniconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
